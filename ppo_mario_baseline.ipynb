{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO Baseline Agent for Super Mario Bros\n",
    "\n",
    "This notebook implements a **baseline PPO agent** trained on the full action space (COMPLEX_MOVEMENT) with the complete reward function. This baseline will be compared against curriculum-trained agents in our research project.\n",
    "\n",
    "## Baseline Configuration:\n",
    "- **Action Space**: COMPLEX_MOVEMENT (12 discrete actions)\n",
    "- **Reward Function**: Full default reward (velocity + time penalty + death penalty)\n",
    "- **Levels**: Configurable - can use hardest levels (World 8) or random stages\n",
    "- **State Space**: Full observation with preprocessing (grayscale, resize, frame stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n",
      "PyTorch version: 2.9.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Tuple, Optional\n",
    "from collections import deque\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Numerical and visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import pandas as pd\n",
    "\n",
    "# We use gymnasium for spaces in some contexts\n",
    "import gymnasium\n",
    "from gymnasium.spaces import Box\n",
    "\n",
    "# Super Mario Bros environment (uses old gym internally)\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Stable Baselines 3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecMonitor, VecTransposeImage\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hyperparameters Configuration\n",
    "\n",
    "All hyperparameters are centralized here for easy modification and ablation studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "--- Environment ---\n",
      "Environment: SuperMarioBros-v0\n",
      "Action Space: 12 actions\n",
      "Actions: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left'], ['left', 'A'], ['left', 'B'], ['left', 'A', 'B'], ['down'], ['up']]\n",
      "\n",
      "--- Preprocessing ---\n",
      "Frame Skip: 4\n",
      "Frame Stack: 4\n",
      "Resize: (84, 84)\n",
      "Grayscale: True\n",
      "\n",
      "--- PPO Hyperparameters ---\n",
      "Learning Rate: 0.00025\n",
      "N Steps: 128\n",
      "Batch Size: 256\n",
      "N Epochs: 4\n",
      "Gamma: 0.99\n",
      "GAE Lambda: 0.95\n",
      "Clip Range: 0.1\n",
      "Entropy Coef: 0.01\n",
      "\n",
      "--- Training ---\n",
      "Total Timesteps: 1,000,000\n",
      "N Envs: 8\n",
      "Device: cpu\n",
      "============================================================\n",
      "✓ Created directories:\n",
      "  Logs: logs/ppo_baseline_20251130_151219\n",
      "  Models: models/ppo_baseline_20251130_151219\n",
      "  TensorBoard: tensorboard/ppo_baseline_20251130_151219\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HYPERPARAMETERS - EASILY MODIFIABLE\n",
    "# ============================================================================\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration for all hyperparameters.\"\"\"\n",
    "    \n",
    "    # ----- ENVIRONMENT SETTINGS -----\n",
    "    ENV_NAME = 'SuperMarioBros-v0'  # Options: 'SuperMarioBros-v0', 'SuperMarioBros-1-1-v0', etc.\n",
    "    # For hardest levels, use specific stages like 'SuperMarioBros-8-4-v0'\n",
    "    # Or use 'SuperMarioBrosRandomStages-v0' with custom stage selection\n",
    "    \n",
    "    ACTION_SPACE = COMPLEX_MOVEMENT  # BASELINE uses full action space\n",
    "    # Options: RIGHT_ONLY (5 actions), SIMPLE_MOVEMENT (7 actions), COMPLEX_MOVEMENT (12 actions)\n",
    "    \n",
    "    # ----- PREPROCESSING SETTINGS -----\n",
    "    FRAME_SKIP = 4           # Number of frames to skip (repeat same action)\n",
    "    FRAME_STACK = 4          # Number of frames to stack for temporal info\n",
    "    RESIZE_SHAPE = (84, 84)  # Resize observation to this shape\n",
    "    GRAYSCALE = True         # Convert to grayscale\n",
    "    NORMALIZE = False         # Keep False - SB3 CnnPolicy normalizes internally\n",
    "    \n",
    "    # ----- PPO HYPERPARAMETERS -----\n",
    "    LEARNING_RATE = 2.5e-4       # Initial learning rate\n",
    "    USE_LR_SCHEDULE = True       # Use linear learning rate decay\n",
    "    N_STEPS = 128                # Steps per environment per update (rollout buffer size)\n",
    "    BATCH_SIZE = 256             # Minibatch size for PPO updates\n",
    "    N_EPOCHS = 4                 # Number of epochs when optimizing the surrogate loss\n",
    "    GAMMA = 0.99                 # Discount factor\n",
    "    GAE_LAMBDA = 0.95            # Factor for Generalized Advantage Estimation\n",
    "    CLIP_RANGE = 0.1             # Clipping parameter for PPO\n",
    "    CLIP_RANGE_VF = None         # Clipping parameter for value function (None = no clipping)\n",
    "    ENT_COEF = 0.02              # Entropy coefficient for exploration\n",
    "    VF_COEF = 0.5                # Value function coefficient in the loss\n",
    "    MAX_GRAD_NORM = 0.5          # Max gradient norm for clipping\n",
    "    \n",
    "    # ----- TRAINING SETTINGS -----\n",
    "    TOTAL_TIMESTEPS = 1_000_000  # Total timesteps for training\n",
    "    N_ENVS = 8                   # Number of parallel environments\n",
    "    EVAL_FREQ = 10000            # Evaluate every N timesteps\n",
    "    EVAL_EPISODES = 5            # Number of episodes for evaluation\n",
    "    SAVE_FREQ = 50000            # Save checkpoint every N timesteps\n",
    "    LOG_INTERVAL = 1             # Log every N updates\n",
    "    VERBOSE = 1                  # Verbosity level\n",
    "    \n",
    "    # ----- PATHS -----\n",
    "    EXPERIMENT_NAME = f\"ppo_baseline_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    LOG_DIR = Path(\"./logs\") / EXPERIMENT_NAME\n",
    "    MODEL_DIR = Path(\"./models\") / EXPERIMENT_NAME\n",
    "    TENSORBOARD_LOG = Path(\"./tensorboard\") / EXPERIMENT_NAME\n",
    "    \n",
    "    # ----- DEVICE -----\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    @classmethod\n",
    "    def create_dirs(cls):\n",
    "        \"\"\"Create necessary directories.\"\"\"\n",
    "        cls.LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        cls.MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "        cls.TENSORBOARD_LOG.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"✓ Created directories:\")\n",
    "        print(f\"  Logs: {cls.LOG_DIR}\")\n",
    "        print(f\"  Models: {cls.MODEL_DIR}\")\n",
    "        print(f\"  TensorBoard: {cls.TENSORBOARD_LOG}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def print_config(cls):\n",
    "        \"\"\"Print current configuration.\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"CONFIGURATION\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"\\n--- Environment ---\")\n",
    "        print(f\"Environment: {cls.ENV_NAME}\")\n",
    "        print(f\"Action Space: {len(cls.ACTION_SPACE)} actions\")\n",
    "        print(f\"Actions: {cls.ACTION_SPACE}\")\n",
    "        print(f\"\\n--- Preprocessing ---\")\n",
    "        print(f\"Frame Skip: {cls.FRAME_SKIP}\")\n",
    "        print(f\"Frame Stack: {cls.FRAME_STACK}\")\n",
    "        print(f\"Resize: {cls.RESIZE_SHAPE}\")\n",
    "        print(f\"Grayscale: {cls.GRAYSCALE}\")\n",
    "        print(f\"\\n--- PPO Hyperparameters ---\")\n",
    "        print(f\"Learning Rate: {cls.LEARNING_RATE}\")\n",
    "        print(f\"N Steps: {cls.N_STEPS}\")\n",
    "        print(f\"Batch Size: {cls.BATCH_SIZE}\")\n",
    "        print(f\"N Epochs: {cls.N_EPOCHS}\")\n",
    "        print(f\"Gamma: {cls.GAMMA}\")\n",
    "        print(f\"GAE Lambda: {cls.GAE_LAMBDA}\")\n",
    "        print(f\"Clip Range: {cls.CLIP_RANGE}\")\n",
    "        print(f\"Entropy Coef: {cls.ENT_COEF}\")\n",
    "        print(f\"\\n--- Training ---\")\n",
    "        print(f\"Total Timesteps: {cls.TOTAL_TIMESTEPS:,}\")\n",
    "        print(f\"N Envs: {cls.N_ENVS}\")\n",
    "        print(f\"Device: {cls.DEVICE}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# Print and create directories\n",
    "Config.print_config()\n",
    "Config.create_dirs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Wrappers for Gymnasium Compatibility\n",
    "\n",
    "These wrappers handle the preprocessing and ensure compatibility with the patched gym-super-mario-bros environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wrappers defined successfully!\n",
      "  - EpisodeInfoWrapper now stores data in 'mario_episode' key\n",
      "  - Tracks MAX x_pos per episode (not just final)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CUSTOM WRAPPERS (Compatible with gym-super-mario-bros and Stable Baselines 3)\n",
    "# ============================================================================\n",
    "# Note: gym-super-mario-bros uses the OLD gym library, not gymnasium.\n",
    "# We inherit from gym.Wrapper for internal wrappers, then use a final\n",
    "# GymnasiumCompatibilityWrapper that inherits from gymnasium.Env to make\n",
    "# the environment compatible with Stable Baselines 3.\n",
    "\n",
    "import gym  # Old gym (required by gym-super-mario-bros)\n",
    "from gym import Wrapper as GymWrapper\n",
    "from gym.spaces import Box as GymBox\n",
    "import gymnasium\n",
    "from gymnasium.spaces import Box as GymnasiumBox\n",
    "from gymnasium.spaces import Discrete as GymnasiumDiscrete\n",
    "import cv2\n",
    "\n",
    "class SkipFrame(GymWrapper):\n",
    "    \"\"\"\n",
    "    Skip frames and repeat the same action.\n",
    "    Accumulates rewards during skipped frames.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, skip: int = 4):\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "        \n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        for _ in range(self._skip):\n",
    "            result = self.env.step(action)\n",
    "            # Handle both 4-tuple and 5-tuple returns\n",
    "            if len(result) == 5:\n",
    "                obs, reward, terminated, truncated, info = result\n",
    "            else:\n",
    "                obs, reward, done, info = result\n",
    "                terminated, truncated = done, False\n",
    "            total_reward += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        return obs, total_reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "class GrayScaleObservation(GymWrapper):\n",
    "    \"\"\"\n",
    "    Convert RGB observation to grayscale.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = GymBox(\n",
    "            low=0, high=255, shape=(*obs_shape, 1), dtype=np.uint8\n",
    "        )\n",
    "    \n",
    "    def _process_obs(self, observation):\n",
    "        gray = np.dot(observation[..., :3], [0.299, 0.587, 0.114])\n",
    "        return gray.astype(np.uint8)[..., np.newaxis]\n",
    "        \n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            return self._process_obs(obs), reward, terminated, truncated, info\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "            return self._process_obs(obs), reward, done, False, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        result = self.env.reset(**kwargs)\n",
    "        if isinstance(result, tuple):\n",
    "            obs, info = result\n",
    "            return self._process_obs(obs), info\n",
    "        return self._process_obs(result), {}\n",
    "\n",
    "\n",
    "class ResizeObservation(GymWrapper):\n",
    "    \"\"\"\n",
    "    Resize observation to specified shape.\n",
    "    \"\"\"\n",
    "    def __init__(self, env, shape: Tuple[int, int]):\n",
    "        super().__init__(env)\n",
    "        self.shape = shape\n",
    "        obs_shape = (*shape, self.observation_space.shape[-1])\n",
    "        self.observation_space = GymBox(\n",
    "            low=0, high=255, shape=obs_shape, dtype=np.uint8\n",
    "        )\n",
    "    \n",
    "    def _process_obs(self, observation):\n",
    "        resized = cv2.resize(\n",
    "            observation, \n",
    "            self.shape, \n",
    "            interpolation=cv2.INTER_AREA\n",
    "        )\n",
    "        if len(resized.shape) == 2:\n",
    "            resized = resized[..., np.newaxis]\n",
    "        return resized\n",
    "        \n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            return self._process_obs(obs), reward, terminated, truncated, info\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "            return self._process_obs(obs), reward, done, False, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        result = self.env.reset(**kwargs)\n",
    "        if isinstance(result, tuple):\n",
    "            obs, info = result\n",
    "            return self._process_obs(obs), info\n",
    "        return self._process_obs(result), {}\n",
    "\n",
    "\n",
    "class NormalizeObservation(GymWrapper):\n",
    "    \"\"\"\n",
    "    Normalize observation to [0, 1] range.\n",
    "    Note: Usually not needed as SB3's CnnPolicy normalizes internally.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = GymBox(\n",
    "            low=0.0, \n",
    "            high=1.0, \n",
    "            shape=self.observation_space.shape, \n",
    "            dtype=np.float32\n",
    "        )\n",
    "    \n",
    "    def _process_obs(self, observation):\n",
    "        return (observation / 255.0).astype(np.float32)\n",
    "        \n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            return self._process_obs(obs), reward, terminated, truncated, info\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "            return self._process_obs(obs), reward, done, False, info\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        result = self.env.reset(**kwargs)\n",
    "        if isinstance(result, tuple):\n",
    "            obs, info = result\n",
    "            return self._process_obs(obs), info\n",
    "        return self._process_obs(result), {}\n",
    "\n",
    "\n",
    "class EpisodeInfoWrapper(GymWrapper):\n",
    "    \"\"\"\n",
    "    Track episode statistics for logging.\n",
    "    \n",
    "    IMPORTANT: Stores episode stats in 'mario_episode' key (not 'episode')\n",
    "    because SB3's VecMonitor OVERWRITES info['episode'].\n",
    "    \n",
    "    Also stores max_x_pos (not just final x_pos) for better progress tracking.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.episode_reward = 0.0\n",
    "        self.episode_length = 0\n",
    "        self.max_x_pos = 0  # Track MAXIMUM x position (not current)\n",
    "        self.current_x_pos = 0\n",
    "        self.episodes_completed = 0\n",
    "        self.flags_gotten = 0\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        self.episode_reward = 0.0\n",
    "        self.episode_length = 0\n",
    "        self.max_x_pos = 0\n",
    "        self.current_x_pos = 0\n",
    "        result = self.env.reset(**kwargs)\n",
    "        if isinstance(result, tuple):\n",
    "            return result\n",
    "        return result, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        \n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "            terminated, truncated = done, False\n",
    "        \n",
    "        self.episode_reward += reward\n",
    "        self.episode_length += 1\n",
    "        \n",
    "        # Track current and max x position\n",
    "        self.current_x_pos = info.get('x_pos', 0)\n",
    "        self.max_x_pos = max(self.max_x_pos, self.current_x_pos)\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            self.episodes_completed += 1\n",
    "            flag_get = info.get('flag_get', False)\n",
    "            if flag_get:\n",
    "                self.flags_gotten += 1\n",
    "            \n",
    "            # Store in 'mario_episode' - VecMonitor won't touch this!\n",
    "            info['mario_episode'] = {\n",
    "                'r': self.episode_reward,\n",
    "                'l': self.episode_length,\n",
    "                'x_pos': self.max_x_pos,  # Use MAX x_pos for the episode\n",
    "                'final_x_pos': self.current_x_pos,\n",
    "                'flag_get': flag_get,\n",
    "                'score': info.get('score', 0),\n",
    "                'time': info.get('time', 0),\n",
    "                'world': info.get('world', 1),\n",
    "                'stage': info.get('stage', 1),\n",
    "            }\n",
    "            \n",
    "            # Also store at top level for easy access\n",
    "            info['episode_x_pos'] = self.max_x_pos\n",
    "            info['episode_flag_get'] = flag_get\n",
    "            \n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "class GymnasiumCompatibilityWrapper(gymnasium.Env):\n",
    "    \"\"\"\n",
    "    Final wrapper that makes the environment fully gymnasium-compatible.\n",
    "    This inherits from gymnasium.Env so that Stable Baselines 3 recognizes\n",
    "    it as a gymnasium environment and doesn't try to use shimmy conversion.\n",
    "    \n",
    "    MUST be the outermost wrapper (applied last).\n",
    "    \"\"\"\n",
    "    metadata = {'render_modes': ['human', 'rgb_array']}\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        \n",
    "        # Convert observation space to gymnasium format\n",
    "        old_obs_space = env.observation_space\n",
    "        self.observation_space = GymnasiumBox(\n",
    "            low=old_obs_space.low.min(),\n",
    "            high=old_obs_space.high.max(),\n",
    "            shape=old_obs_space.shape,\n",
    "            dtype=old_obs_space.dtype\n",
    "        )\n",
    "        \n",
    "        # Convert action space to gymnasium format\n",
    "        old_action_space = env.action_space\n",
    "        self.action_space = GymnasiumDiscrete(old_action_space.n)\n",
    "        \n",
    "        # Copy other attributes\n",
    "        self.reward_range = getattr(env, 'reward_range', (-float('inf'), float('inf')))\n",
    "        self.spec = getattr(env, 'spec', None)\n",
    "    \n",
    "    def step(self, action):\n",
    "        result = self.env.step(action)\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "            terminated, truncated = done, False\n",
    "        return obs, float(reward), bool(terminated), bool(truncated), info\n",
    "    \n",
    "    def reset(self, seed=None, options=None):\n",
    "        # Handle seed if provided\n",
    "        if seed is not None and hasattr(self.env, 'seed'):\n",
    "            self.env.seed(seed)\n",
    "        \n",
    "        result = self.env.reset()\n",
    "        if isinstance(result, tuple):\n",
    "            obs, info = result\n",
    "        else:\n",
    "            obs, info = result, {}\n",
    "        return obs, info\n",
    "    \n",
    "    def render(self):\n",
    "        if hasattr(self.env, 'render'):\n",
    "            return self.env.render()\n",
    "        return None\n",
    "    \n",
    "    def close(self):\n",
    "        if hasattr(self.env, 'close'):\n",
    "            return self.env.close()\n",
    "    \n",
    "    @property\n",
    "    def unwrapped(self):\n",
    "        return self.env.unwrapped if hasattr(self.env, 'unwrapped') else self.env\n",
    "\n",
    "\n",
    "print(\"✓ Wrappers defined successfully!\")\n",
    "print(\"  - EpisodeInfoWrapper now stores data in 'mario_episode' key\")\n",
    "print(\"  - Tracks MAX x_pos per episode (not just final)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Environment Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment factory defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENVIRONMENT FACTORY\n",
    "# ============================================================================\n",
    "\n",
    "def make_mario_env(\n",
    "    env_name: str = Config.ENV_NAME,\n",
    "    action_space = Config.ACTION_SPACE,\n",
    "    frame_skip: int = Config.FRAME_SKIP,\n",
    "    resize_shape: Tuple[int, int] = Config.RESIZE_SHAPE,\n",
    "    grayscale: bool = Config.GRAYSCALE,\n",
    "    normalize: bool = Config.NORMALIZE,\n",
    "    rank: int = 0,\n",
    "    seed: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Factory function to create a preprocessed Mario environment.\n",
    "    \n",
    "    Args:\n",
    "        env_name: Name of the environment\n",
    "        action_space: Action space to use (RIGHT_ONLY, SIMPLE_MOVEMENT, COMPLEX_MOVEMENT)\n",
    "        frame_skip: Number of frames to skip\n",
    "        resize_shape: Shape to resize observations to\n",
    "        grayscale: Whether to convert to grayscale\n",
    "        normalize: Whether to normalize pixel values\n",
    "        rank: Rank of the environment (for parallel envs)\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        Callable that creates the environment\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        # Create base environment\n",
    "        env = gym_super_mario_bros.make(env_name)\n",
    "        \n",
    "        # Apply JoypadSpace wrapper for action space\n",
    "        env = JoypadSpace(env, action_space)\n",
    "        \n",
    "        # Episode info tracking\n",
    "        env = EpisodeInfoWrapper(env)\n",
    "        \n",
    "        # Frame skipping\n",
    "        if frame_skip > 1:\n",
    "            env = SkipFrame(env, skip=frame_skip)\n",
    "        \n",
    "        # Grayscale\n",
    "        if grayscale:\n",
    "            env = GrayScaleObservation(env)\n",
    "        \n",
    "        # Resize\n",
    "        if resize_shape is not None:\n",
    "            env = ResizeObservation(env, shape=resize_shape)\n",
    "        \n",
    "        # Normalize (usually False - SB3 CnnPolicy normalizes internally)\n",
    "        if normalize:\n",
    "            env = NormalizeObservation(env)\n",
    "        \n",
    "        # IMPORTANT: Final wrapper to make it gymnasium-compatible for SB3\n",
    "        # This MUST be the last wrapper applied\n",
    "        env = GymnasiumCompatibilityWrapper(env)\n",
    "        \n",
    "        return env\n",
    "    \n",
    "    return _init\n",
    "\n",
    "\n",
    "def create_vectorized_env(\n",
    "    n_envs: int = Config.N_ENVS,\n",
    "    frame_stack: int = Config.FRAME_STACK,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Create vectorized environment with frame stacking.\n",
    "    \n",
    "    Args:\n",
    "        n_envs: Number of parallel environments\n",
    "        frame_stack: Number of frames to stack\n",
    "        **kwargs: Additional arguments passed to make_mario_env\n",
    "    \n",
    "    Returns:\n",
    "        Vectorized environment\n",
    "    \"\"\"\n",
    "    # Create environment factories\n",
    "    env_fns = [make_mario_env(rank=i, **kwargs) for i in range(n_envs)]\n",
    "    \n",
    "    # Create vectorized environment\n",
    "    vec_env = DummyVecEnv(env_fns)\n",
    "    \n",
    "    # Add monitoring\n",
    "    vec_env = VecMonitor(vec_env)\n",
    "    \n",
    "    # Add frame stacking\n",
    "    if frame_stack > 1:\n",
    "        vec_env = VecFrameStack(vec_env, n_stack=frame_stack, channels_order='last')\n",
    "    \n",
    "    # Transpose for PyTorch (channels first)\n",
    "    vec_env = VecTransposeImage(vec_env)\n",
    "    \n",
    "    return vec_env\n",
    "\n",
    "\n",
    "print(\"✓ Environment factory defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing environment setup...\n",
      "\n",
      "✓ Environment created: SuperMarioBros-v0\n",
      "  Environment type: GymnasiumCompatibilityWrapper\n",
      "  Is gymnasium.Env: True\n",
      "  Observation space: Box(0, 255, (84, 84, 1), uint8)\n",
      "  Action space: Discrete(12)\n",
      "  Number of actions: 12\n",
      "\n",
      "✓ Reset successful\n",
      "  Observation shape: (84, 84, 1)\n",
      "  Observation dtype: uint8\n",
      "  Observation range: [21.000, 252.000]\n",
      "\n",
      "✓ Step returns 5 values (gymnasium-compatible)\n",
      "  Reward: 0.0\n",
      "  Terminated: False\n",
      "  Truncated: False\n",
      "  Info keys: ['coins', 'flag_get', 'life', 'score', 'stage', 'status', 'time', 'world', 'x_pos', 'y_pos']\n",
      "\n",
      "--------------------------------------------------\n",
      "Testing vectorized environment...\n",
      "\n",
      "✓ Vectorized environment created\n",
      "  Number of envs: 2\n",
      "  Observation space: Box(0, 255, (4, 84, 84), uint8)\n",
      "  Action space: Discrete(12)\n",
      "  Observation shape after reset: (2, 4, 84, 84)\n",
      "  Expected shape: (2, 4, 84, 84)\n",
      "  Observation shape after steps: (2, 4, 84, 84)\n",
      "  Observation dtype: uint8\n",
      "\n",
      "✓ All environment tests passed!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VERIFY ENVIRONMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Testing environment setup...\\n\")\n",
    "\n",
    "# Create single test environment\n",
    "test_env_fn = make_mario_env()\n",
    "test_env = test_env_fn()\n",
    "\n",
    "print(f\"✓ Environment created: {Config.ENV_NAME}\")\n",
    "print(f\"  Environment type: {type(test_env).__name__}\")\n",
    "print(f\"  Is gymnasium.Env: {isinstance(test_env, gymnasium.Env)}\")\n",
    "print(f\"  Observation space: {test_env.observation_space}\")\n",
    "print(f\"  Action space: {test_env.action_space}\")\n",
    "print(f\"  Number of actions: {test_env.action_space.n}\")\n",
    "\n",
    "# Test reset\n",
    "obs, info = test_env.reset()\n",
    "print(f\"\\n✓ Reset successful\")\n",
    "print(f\"  Observation shape: {obs.shape}\")\n",
    "print(f\"  Observation dtype: {obs.dtype}\")\n",
    "print(f\"  Observation range: [{obs.min():.3f}, {obs.max():.3f}]\")\n",
    "\n",
    "# Test step\n",
    "action = test_env.action_space.sample()\n",
    "obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "\n",
    "print(f\"\\n✓ Step returns 5 values (gymnasium-compatible)\")\n",
    "print(f\"  Reward: {reward}\")\n",
    "print(f\"  Terminated: {terminated}\")\n",
    "print(f\"  Truncated: {truncated}\")\n",
    "print(f\"  Info keys: {list(info.keys())}\")\n",
    "\n",
    "# Close test environment\n",
    "test_env.close()\n",
    "\n",
    "# Test vectorized environment\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"Testing vectorized environment...\\n\")\n",
    "\n",
    "vec_env = create_vectorized_env(n_envs=2)\n",
    "print(f\"✓ Vectorized environment created\")\n",
    "print(f\"  Number of envs: {vec_env.num_envs}\")\n",
    "print(f\"  Observation space: {vec_env.observation_space}\")\n",
    "print(f\"  Action space: {vec_env.action_space}\")\n",
    "\n",
    "obs = vec_env.reset()\n",
    "print(f\"  Observation shape after reset: {obs.shape}\")\n",
    "print(f\"  Expected shape: (2, {Config.FRAME_STACK}, {Config.RESIZE_SHAPE[0]}, {Config.RESIZE_SHAPE[1]})\")\n",
    "\n",
    "# Test a few steps\n",
    "for i in range(5):\n",
    "    actions = [vec_env.action_space.sample() for _ in range(vec_env.num_envs)]\n",
    "    obs, rewards, dones, infos = vec_env.step(actions)\n",
    "\n",
    "print(f\"  Observation shape after steps: {obs.shape}\")\n",
    "print(f\"  Observation dtype: {obs.dtype}\")\n",
    "\n",
    "vec_env.close()\n",
    "print(\"\\n✓ All environment tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Preprocessed Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZE OBSERVATIONS\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_frame_stack(obs, title=\"Frame Stack Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualize stacked frames from the environment.\n",
    "    \n",
    "    Args:\n",
    "        obs: Observation array (channels, height, width) or (batch, channels, height, width)\n",
    "        title: Title for the plot\n",
    "    \"\"\"\n",
    "    # Handle batched observations\n",
    "    if len(obs.shape) == 4:\n",
    "        obs = obs[0]  # Take first environment\n",
    "    \n",
    "    n_frames = obs.shape[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_frames, figsize=(4*n_frames, 4))\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    \n",
    "    for i in range(n_frames):\n",
    "        ax = axes[i] if n_frames > 1 else axes\n",
    "        frame = obs[i]\n",
    "        ax.imshow(frame, cmap='gray')\n",
    "        ax.set_title(f\"Frame {i+1}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create environment and visualize\n",
    "vec_env = create_vectorized_env(n_envs=1)\n",
    "obs = vec_env.reset()\n",
    "\n",
    "# Take a few random steps to see different frames\n",
    "for _ in range(20):\n",
    "    action = [vec_env.action_space.sample()]\n",
    "    obs, _, _, _ = vec_env.step(action)\n",
    "\n",
    "visualize_frame_stack(obs, \"Preprocessed Frame Stack (after 20 steps)\")\n",
    "\n",
    "vec_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom CNN Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Custom CNN feature extractor defined!\n",
      "  Features dimension: 512\n",
      "  Policy network: [256]\n",
      "  Value network: [256]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CUSTOM CNN FEATURE EXTRACTOR\n",
    "# ============================================================================\n",
    "\n",
    "class MarioCNN(BaseFeaturesExtractor):\n",
    "    \"\"\"\n",
    "    Custom CNN feature extractor for Mario.\n",
    "    Architecture inspired by Nature DQN paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, observation_space, features_dim: int = 512):\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        \n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        # Compute the output size of CNN\n",
    "        with torch.no_grad():\n",
    "            sample = torch.zeros(1, *observation_space.shape)\n",
    "            n_flatten = self.cnn(sample).shape[1]\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(n_flatten, features_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, observations):\n",
    "        return self.linear(self.cnn(observations))\n",
    "\n",
    "\n",
    "# Policy kwargs for PPO\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MarioCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=512),\n",
    "    net_arch=dict(pi=[256], vf=[256]),  # Separate networks for policy and value\n",
    "    activation_fn=nn.ReLU,\n",
    ")\n",
    "\n",
    "print(\"✓ Custom CNN feature extractor defined!\")\n",
    "print(f\"  Features dimension: 512\")\n",
    "print(f\"  Policy network: [256]\")\n",
    "print(f\"  Value network: [256]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Callbacks defined: TrainingMetricsCallback, SaveBestModelCallback, HeartbeatCallback\n",
      "  - TrainingMetricsCallback now reads from 'mario_episode' key\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING CALLBACKS\n",
    "# ============================================================================\n",
    "\n",
    "import time as _time  # Import at module level to avoid recursion issues\n",
    "\n",
    "class TrainingMetricsCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback to track and save training metrics.\n",
    "    \n",
    "    IMPORTANT: Reads from 'mario_episode' key (not 'episode') because\n",
    "    SB3's VecMonitor overwrites info['episode'].\n",
    "    \"\"\"\n",
    "    def __init__(self, check_freq: int = 1000, log_dir: Path = None, verbose: int = 1):\n",
    "        super().__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.log_dir = log_dir\n",
    "        self.metrics = {\n",
    "            'timesteps': [],\n",
    "            'episode_rewards': [],\n",
    "            'episode_lengths': [],\n",
    "            'x_positions': [],\n",
    "            'flags_gotten': []\n",
    "        }\n",
    "        self.episode_rewards = deque(maxlen=100)\n",
    "        self.episode_lengths = deque(maxlen=100)\n",
    "        self.x_positions = deque(maxlen=100)\n",
    "        self.flags_gotten = deque(maxlen=100)\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        # Check for episode completions in info\n",
    "        for info in self.locals.get('infos', []):\n",
    "            # Read from 'mario_episode' - our custom key that VecMonitor doesn't touch\n",
    "            if 'mario_episode' in info:\n",
    "                ep_info = info['mario_episode']\n",
    "                self.episode_rewards.append(ep_info['r'])\n",
    "                self.episode_lengths.append(ep_info['l'])\n",
    "                self.x_positions.append(ep_info.get('x_pos', 0))\n",
    "                self.flags_gotten.append(1 if ep_info.get('flag_get', False) else 0)\n",
    "            # Fallback: also check top-level keys we set\n",
    "            elif 'episode_x_pos' in info:\n",
    "                # Get reward/length from VecMonitor's 'episode' key\n",
    "                if 'episode' in info:\n",
    "                    vec_ep = info['episode']\n",
    "                    self.episode_rewards.append(vec_ep.get('r', 0))\n",
    "                    self.episode_lengths.append(vec_ep.get('l', 0))\n",
    "                self.x_positions.append(info.get('episode_x_pos', 0))\n",
    "                self.flags_gotten.append(1 if info.get('episode_flag_get', False) else 0)\n",
    "        \n",
    "        # Log metrics at check_freq\n",
    "        if self.n_calls % self.check_freq == 0 and len(self.episode_rewards) > 0:\n",
    "            self.metrics['timesteps'].append(self.num_timesteps)\n",
    "            self.metrics['episode_rewards'].append(np.mean(self.episode_rewards))\n",
    "            self.metrics['episode_lengths'].append(np.mean(self.episode_lengths))\n",
    "            self.metrics['x_positions'].append(np.mean(self.x_positions))\n",
    "            self.metrics['flags_gotten'].append(np.mean(self.flags_gotten))\n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                print(f\"  Step {self.num_timesteps:,}: \"\n",
    "                      f\"reward={np.mean(self.episode_rewards):.1f}, \"\n",
    "                      f\"x_pos={np.mean(self.x_positions):.0f}, \"\n",
    "                      f\"flags={np.sum(self.flags_gotten)}/{len(self.flags_gotten)}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _on_training_end(self):\n",
    "        # Save metrics to CSV\n",
    "        if self.log_dir:\n",
    "            self.log_dir.mkdir(parents=True, exist_ok=True)\n",
    "            df = pd.DataFrame(self.metrics)\n",
    "            df.to_csv(self.log_dir / 'training_metrics.csv', index=False)\n",
    "            if self.verbose > 0:\n",
    "                print(f\"\\n✓ Metrics saved to {self.log_dir / 'training_metrics.csv'}\")\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"Return collected metrics.\"\"\"\n",
    "        return self.metrics\n",
    "\n",
    "\n",
    "class SaveBestModelCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback to save the best model based on mean reward.\n",
    "    \"\"\"\n",
    "    def __init__(self, save_path: Path, check_freq: int = 10000, verbose: int = 1):\n",
    "        super().__init__(verbose)\n",
    "        self.save_path = save_path\n",
    "        self.check_freq = check_freq\n",
    "        self.best_mean_reward = -np.inf\n",
    "        self.episode_rewards = deque(maxlen=100)\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        # Track episode rewards - check both our key and VecMonitor's key\n",
    "        for info in self.locals.get('infos', []):\n",
    "            if 'mario_episode' in info:\n",
    "                self.episode_rewards.append(info['mario_episode']['r'])\n",
    "            elif 'episode' in info:\n",
    "                self.episode_rewards.append(info['episode']['r'])\n",
    "        \n",
    "        # Check if we should evaluate\n",
    "        if self.n_calls % self.check_freq == 0 and len(self.episode_rewards) >= 10:\n",
    "            mean_reward = np.mean(self.episode_rewards)\n",
    "            \n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                self.best_mean_reward = mean_reward\n",
    "                self.save_path.mkdir(parents=True, exist_ok=True)\n",
    "                save_file = self.save_path / 'best_model'\n",
    "                self.model.save(save_file)\n",
    "                if self.verbose > 0:\n",
    "                    print(f\"  ★ New best model! Mean reward: {mean_reward:.2f} -> {save_file}\")\n",
    "        \n",
    "        return True\n",
    "\n",
    "\n",
    "class HeartbeatCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Callback that prints periodic status updates to prevent silent timeouts.\n",
    "    Also helps detect if training has stalled.\n",
    "    \n",
    "    Note: Uses module-level _time import to avoid recursion issues with inspect.\n",
    "    \"\"\"\n",
    "    def __init__(self, interval: int = 30, verbose: int = 1):\n",
    "        super().__init__(verbose)\n",
    "        self.interval = interval  # seconds between heartbeats\n",
    "        self.last_heartbeat = None\n",
    "        self.last_timestep = 0\n",
    "        self.start_time = None\n",
    "        \n",
    "    def _on_training_start(self):\n",
    "        self.start_time = _time.time()\n",
    "        self.last_heartbeat = _time.time()\n",
    "        self.last_timestep = 0\n",
    "        if self.verbose > 0:\n",
    "            print(f\"[Heartbeat] Training started at {datetime.datetime.now().strftime('%H:%M:%S')}\")\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        current_time = _time.time()\n",
    "        \n",
    "        # Print heartbeat every interval seconds\n",
    "        if current_time - self.last_heartbeat >= self.interval:\n",
    "            elapsed = current_time - self.start_time\n",
    "            steps_since_last = self.num_timesteps - self.last_timestep\n",
    "            steps_per_sec = steps_since_last / self.interval if self.interval > 0 else 0\n",
    "            \n",
    "            # Calculate ETA\n",
    "            total_timesteps = self.locals.get('total_timesteps', Config.TOTAL_TIMESTEPS)\n",
    "            remaining_steps = total_timesteps - self.num_timesteps\n",
    "            eta_seconds = remaining_steps / steps_per_sec if steps_per_sec > 0 else 0\n",
    "            \n",
    "            hours = int(elapsed // 3600)\n",
    "            minutes = int((elapsed % 3600) // 60)\n",
    "            seconds = int(elapsed % 60)\n",
    "            \n",
    "            eta_hours = int(eta_seconds // 3600)\n",
    "            eta_minutes = int((eta_seconds % 3600) // 60)\n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                print(f\"[Heartbeat] {self.num_timesteps:,}/{total_timesteps:,} steps \"\n",
    "                      f\"({100*self.num_timesteps/total_timesteps:.1f}%) | \"\n",
    "                      f\"Elapsed: {hours}h{minutes:02d}m{seconds:02d}s | \"\n",
    "                      f\"Speed: {steps_per_sec:.0f} steps/s | \"\n",
    "                      f\"ETA: {eta_hours}h{eta_minutes:02d}m\")\n",
    "            \n",
    "            self.last_heartbeat = current_time\n",
    "            self.last_timestep = self.num_timesteps\n",
    "            \n",
    "            # Flush output to ensure it's displayed\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _on_training_end(self):\n",
    "        if self.verbose > 0 and self.start_time is not None:\n",
    "            elapsed = _time.time() - self.start_time\n",
    "            hours = int(elapsed // 3600)\n",
    "            minutes = int((elapsed % 3600) // 60)\n",
    "            seconds = int(elapsed % 60)\n",
    "            print(f\"[Heartbeat] Training ended. Total time: {hours}h{minutes:02d}m{seconds:02d}s\")\n",
    "\n",
    "\n",
    "print(\"✓ Callbacks defined: TrainingMetricsCallback, SaveBestModelCallback, HeartbeatCallback\")\n",
    "print(\"  - TrainingMetricsCallback now reads from 'mario_episode' key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Learning rate schedules defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LEARNING RATE SCHEDULE\n",
    "# ============================================================================\n",
    "\n",
    "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "    \n",
    "    Args:\n",
    "        initial_value: Initial learning rate\n",
    "    \n",
    "    Returns:\n",
    "        Schedule function that computes current learning rate\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0 (end).\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "    return func\n",
    "\n",
    "\n",
    "def cosine_schedule(initial_value: float, min_value: float = 1e-6) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Cosine annealing learning rate schedule.\n",
    "    \"\"\"\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        return min_value + 0.5 * (initial_value - min_value) * (1 + np.cos(np.pi * (1 - progress_remaining)))\n",
    "    return func\n",
    "\n",
    "\n",
    "# Visualize learning rate schedules\n",
    "progress = np.linspace(1, 0, 100)\n",
    "linear_lr = [linear_schedule(Config.LEARNING_RATE)(p) for p in progress]\n",
    "cosine_lr = [cosine_schedule(Config.LEARNING_RATE)(p) for p in progress]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(1 - progress, linear_lr, label='Linear Schedule', linewidth=2)\n",
    "plt.plot(1 - progress, cosine_lr, label='Cosine Schedule', linewidth=2)\n",
    "plt.xlabel('Training Progress')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Learning Rate Schedules')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Learning rate schedules defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard Diagnostic\n",
      "==================================================\n",
      "✓ tensorboard package version: 2.14.0\n",
      "✓ torch.utils.tensorboard.SummaryWriter importable\n",
      "✓ SummaryWriter creation works\n",
      "✓ SB3 internal SummaryWriter: Available\n",
      "✓ protobuf version: 6.33.1\n",
      "\n",
      "==================================================\n",
      "✓ TensorBoard is properly configured!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TENSORBOARD DIAGNOSTICS (Optional - Run if TensorBoard issues)\n",
    "# ============================================================================\n",
    "# This cell diagnoses TensorBoard installation issues.\n",
    "# Run it if you encounter TensorBoard import errors during training.\n",
    "\n",
    "print(\"TensorBoard Diagnostic\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check tensorboard package\n",
    "try:\n",
    "    import tensorboard\n",
    "    print(f\"✓ tensorboard package version: {tensorboard.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ tensorboard package not found: {e}\")\n",
    "\n",
    "# Check torch.utils.tensorboard (direct import)\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    print(f\"✓ torch.utils.tensorboard.SummaryWriter importable\")\n",
    "    # Try creating a writer\n",
    "    import tempfile\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        writer = SummaryWriter(tmpdir)\n",
    "        writer.close()\n",
    "        print(f\"✓ SummaryWriter creation works\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ torch.utils.tensorboard import failed: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ SummaryWriter creation failed: {e}\")\n",
    "\n",
    "# Check what SB3 thinks about TensorBoard\n",
    "from stable_baselines3.common import utils as sb3_utils\n",
    "sb3_has_tb = hasattr(sb3_utils, 'SummaryWriter') and sb3_utils.SummaryWriter is not None\n",
    "print(f\"{'✓' if sb3_has_tb else '✗'} SB3 internal SummaryWriter: {'Available' if sb3_has_tb else 'None'}\")\n",
    "\n",
    "# Check protobuf (common cause of tensorboard issues)\n",
    "try:\n",
    "    import google.protobuf\n",
    "    print(f\"✓ protobuf version: {google.protobuf.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ protobuf not found: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if not sb3_has_tb:\n",
    "    print(\"⚠ TensorBoard is NOT available for Stable Baselines 3\")\n",
    "    print(\"\\nTo fix this issue, try the following in your terminal:\")\n",
    "    print(\"  1. pip uninstall tensorboard tensorboard-data-server -y\")\n",
    "    print(\"  2. pip install tensorboard==2.14.0 --break-system-packages\")\n",
    "    print(\"  3. Restart your Jupyter kernel completely\")\n",
    "    print(\"\\nAlternatively, training will work fine without TensorBoard.\")\n",
    "    print(\"Metrics are also saved to CSV files.\")\n",
    "else:\n",
    "    print(\"✓ TensorBoard is properly configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Create and Initialize PPO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ TensorBoard is available (SB3 internal check passed)\n",
      "\n",
      "Creating training environment...\n",
      "✓ Training environment ready: 8 parallel envs\n",
      "\n",
      "Creating evaluation environment...\n",
      "✓ Evaluation environment ready\n",
      "\n",
      "Using linear learning rate schedule (initial: 0.00025)\n",
      "\n",
      "Initializing PPO model...\n",
      "Using cpu device\n",
      "\n",
      "✓ PPO Model created!\n",
      "  Policy: ActorCriticCnnPolicy\n",
      "  Device: cpu\n",
      "  TensorBoard logging: Enabled\n",
      "\n",
      "==================================================\n",
      "MODEL ARCHITECTURE\n",
      "==================================================\n",
      "ActorCriticCnnPolicy(\n",
      "  (features_extractor): MarioCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pi_features_extractor): MarioCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (vf_features_extractor): MarioCNN(\n",
      "    (cnn): Sequential(\n",
      "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "      (1): ReLU()\n",
      "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "      (3): ReLU()\n",
      "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (5): ReLU()\n",
      "      (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    )\n",
      "    (linear): Sequential(\n",
      "      (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=256, out_features=12, bias=True)\n",
      "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE PPO MODEL\n",
    "# ============================================================================\n",
    "\n",
    "# Check if TensorBoard is ACTUALLY available for Stable Baselines 3\n",
    "# SB3 caches its own import check at module load time, so we need to check\n",
    "# SB3's internal state, not just try importing ourselves.\n",
    "\n",
    "from stable_baselines3.common import utils as sb3_utils\n",
    "\n",
    "# Check SB3's internal SummaryWriter (this is what SB3 actually uses)\n",
    "tensorboard_available = hasattr(sb3_utils, 'SummaryWriter') and sb3_utils.SummaryWriter is not None\n",
    "\n",
    "if tensorboard_available:\n",
    "    print(\"✓ TensorBoard is available (SB3 internal check passed)\")\n",
    "else:\n",
    "    print(\"⚠ TensorBoard not available for Stable Baselines 3\")\n",
    "    print(\"  This usually happens due to version mismatches.\")\n",
    "    print(\"  Training will proceed without TensorBoard logging.\")\n",
    "    print(\"\\n  To fix, try running in your terminal:\")\n",
    "    print(\"    pip uninstall tensorboard tensorboard-data-server -y\")\n",
    "    print(\"    pip install tensorboard==2.14.0 --break-system-packages\")\n",
    "    print(\"    # Then restart your Jupyter kernel\")\n",
    "\n",
    "# Set tensorboard log path (None if not available)\n",
    "tb_log_path = str(Config.TENSORBOARD_LOG) if tensorboard_available else None\n",
    "\n",
    "# Create vectorized environment\n",
    "print(\"\\nCreating training environment...\")\n",
    "train_env = create_vectorized_env(n_envs=Config.N_ENVS)\n",
    "print(f\"✓ Training environment ready: {Config.N_ENVS} parallel envs\")\n",
    "\n",
    "# Create evaluation environment\n",
    "print(\"\\nCreating evaluation environment...\")\n",
    "eval_env = create_vectorized_env(n_envs=1)\n",
    "print(f\"✓ Evaluation environment ready\")\n",
    "\n",
    "# Set up learning rate\n",
    "if Config.USE_LR_SCHEDULE:\n",
    "    learning_rate = linear_schedule(Config.LEARNING_RATE)\n",
    "    print(f\"\\nUsing linear learning rate schedule (initial: {Config.LEARNING_RATE})\")\n",
    "else:\n",
    "    learning_rate = Config.LEARNING_RATE\n",
    "    print(f\"\\nUsing constant learning rate: {Config.LEARNING_RATE}\")\n",
    "\n",
    "# Create PPO model\n",
    "print(\"\\nInitializing PPO model...\")\n",
    "model = PPO(\n",
    "    policy='CnnPolicy',\n",
    "    env=train_env,\n",
    "    learning_rate=learning_rate,\n",
    "    n_steps=Config.N_STEPS,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    n_epochs=Config.N_EPOCHS,\n",
    "    gamma=Config.GAMMA,\n",
    "    gae_lambda=Config.GAE_LAMBDA,\n",
    "    clip_range=Config.CLIP_RANGE,\n",
    "    clip_range_vf=Config.CLIP_RANGE_VF,\n",
    "    ent_coef=Config.ENT_COEF,\n",
    "    vf_coef=Config.VF_COEF,\n",
    "    max_grad_norm=Config.MAX_GRAD_NORM,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    tensorboard_log=tb_log_path,  # None if tensorboard not available\n",
    "    verbose=Config.VERBOSE,\n",
    "    device=Config.DEVICE\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ PPO Model created!\")\n",
    "print(f\"  Policy: {model.policy.__class__.__name__}\")\n",
    "print(f\"  Device: {model.device}\")\n",
    "print(f\"  TensorBoard logging: {'Enabled' if tb_log_path else 'Disabled (metrics saved to CSV)'}\")\n",
    "\n",
    "# Print model summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*50)\n",
    "print(model.policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10b. Evaluation Function\n",
    "\n",
    "This function is used by both trial run and full training to evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ evaluate_model function defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVALUATE TRAINED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(\n",
    "    model, \n",
    "    env, \n",
    "    n_episodes: int = 10,\n",
    "    deterministic: bool = False,\n",
    "    verbose: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate the trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PPO model\n",
    "        env: Evaluation environment\n",
    "        n_episodes: Number of episodes to evaluate\n",
    "        deterministic: Use deterministic actions (False gives more variance)\n",
    "        verbose: Print episode details\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing evaluation metrics.\n",
    "        Note: completion_rate is returned as a FRACTION (0.0-1.0), not percentage.\n",
    "    \"\"\"\n",
    "    episode_rewards = []\n",
    "    episode_lengths = []\n",
    "    episode_x_positions = []\n",
    "    flags_gotten = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        episode_length = 0\n",
    "        done = False\n",
    "        max_x_pos = 0\n",
    "        flag_get = False\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=deterministic)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            \n",
    "            episode_reward += reward[0]\n",
    "            episode_length += 1\n",
    "            \n",
    "            # Track x position from info (at top level from Mario env)\n",
    "            current_x = info[0].get('x_pos', 0)\n",
    "            max_x_pos = max(max_x_pos, current_x)\n",
    "            \n",
    "            # Check for flag\n",
    "            if info[0].get('flag_get', False):\n",
    "                flag_get = True\n",
    "        \n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_lengths.append(episode_length)\n",
    "        episode_x_positions.append(max_x_pos)\n",
    "        flags_gotten.append(1 if flag_get else 0)\n",
    "        \n",
    "        if verbose:\n",
    "            flag_str = \"✓ FLAG\" if flag_get else \"\"\n",
    "            print(f\"Episode {episode+1:3d}: Reward={episode_reward:8.2f}, \"\n",
    "                  f\"Length={episode_length:5d}, X_pos={max_x_pos:5d} {flag_str}\")\n",
    "    \n",
    "    # completion_rate is a FRACTION (0.0-1.0)\n",
    "    completion_rate = np.mean(flags_gotten)\n",
    "    \n",
    "    results = {\n",
    "        'mean_reward': np.mean(episode_rewards),\n",
    "        'std_reward': np.std(episode_rewards),\n",
    "        'mean_length': np.mean(episode_lengths),\n",
    "        'std_length': np.std(episode_lengths),\n",
    "        'mean_x_pos': np.mean(episode_x_positions),\n",
    "        'std_x_pos': np.std(episode_x_positions),\n",
    "        'max_x_pos': np.max(episode_x_positions),\n",
    "        'min_x_pos': np.min(episode_x_positions),\n",
    "        'total_flags': np.sum(flags_gotten),\n",
    "        'completion_rate': completion_rate,  # FRACTION, not percentage!\n",
    "        'episode_rewards': episode_rewards,\n",
    "        'episode_lengths': episode_lengths,\n",
    "        'episode_x_positions': episode_x_positions\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EVALUATION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Episodes: {n_episodes}\")\n",
    "    print(f\"Mean Reward: {results['mean_reward']:.2f} ± {results['std_reward']:.2f}\")\n",
    "    print(f\"Mean Episode Length: {results['mean_length']:.2f} ± {results['std_length']:.2f}\")\n",
    "    print(f\"Mean X Position: {results['mean_x_pos']:.2f} ± {results['std_x_pos']:.2f}\")\n",
    "    print(f\"X Position Range: [{results['min_x_pos']}, {results['max_x_pos']}]\")\n",
    "    print(f\"Level Completions: {results['total_flags']}/{n_episodes}\")\n",
    "    print(f\"Completion Rate: {results['completion_rate']*100:.1f}%\")\n",
    "    \n",
    "    # Warn if no variance (might indicate policy collapse)\n",
    "    if results['std_reward'] == 0 and n_episodes > 1:\n",
    "        print(\"\\n⚠ WARNING: Zero variance in rewards!\")\n",
    "        print(\"  This might indicate the policy has collapsed to a single action.\")\n",
    "        print(\"  Try running with deterministic=False to see stochastic behavior.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"✓ evaluate_model function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11a. Trial Run (Quick Verification)\n",
    "\n",
    "Run this cell FIRST to verify everything works end-to-end before committing to full training.\n",
    "This runs a short training session (~50k steps), evaluates the agent, and plots results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRIAL RUN - End-to-End Verification\n",
      "============================================================\n",
      "Trial timesteps: 50,000\n",
      "Using same Config values as full training\n",
      "============================================================\n",
      "\n",
      "Creating trial environments...\n",
      "✓ Trial environments ready (4 training envs)\n",
      "\n",
      "Creating trial model...\n",
      "✓ Trial model created on cpu\n",
      "\n",
      "----------------------------------------\n",
      "Starting trial training...\n",
      "----------------------------------------\n",
      "[Heartbeat] Training started at 15:12:30\n",
      "[Heartbeat] 1,060/50,000 steps (2.1%) | Elapsed: 0h00m15s | Speed: 71 steps/s | ETA: 0h11m\n",
      "[Heartbeat] 2,156/50,000 steps (4.3%) | Elapsed: 0h00m30s | Speed: 73 steps/s | ETA: 0h10m\n",
      "\n",
      "\n",
      "⚠ Trial interrupted by user\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mtrial_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRIAL_TIMESTEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial_callbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLOG_INTERVAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Disabled: conflicts with Jupyter/Rich\u001b[39;49;00m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     trial_training_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m trial_start_time\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Trial training complete in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_training_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    304\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:337\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdump_logs(iteration)\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py:213\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mDiscrete):\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# Convert discrete action from float to long\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     actions \u001b[38;5;241m=\u001b[39m rollout_data\u001b[38;5;241m.\u001b[39mactions\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m--> 213\u001b[0m values, log_prob, entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Normalize advantage\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/stable_baselines3/common/policies.py:730\u001b[0m, in \u001b[0;36mActorCriticPolicy.evaluate_actions\u001b[0;34m(self, obs, actions)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03mEvaluate actions according to the current policy,\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03mgiven the observations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m    and entropy of the action distribution.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n\u001b[0;32m--> 730\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m    732\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor(features)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/stable_baselines3/common/policies.py:672\u001b[0m, in \u001b[0;36mActorCriticPolicy.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;124;03m    features for the actor and the features for the critic.\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[0;32m--> 672\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/stable_baselines3/common/policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[0;34m(self, obs, features_extractor)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m:return: The extracted features\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m preprocessed_obs \u001b[38;5;241m=\u001b[39m preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, normalize_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_images)\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 36\u001b[0m, in \u001b[0;36mMarioCNN.forward\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/mario_env2/lib/python3.10/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRIAL RUN - Quick End-to-End Verification\n",
    "# ============================================================================\n",
    "# This runs a SHORT training session using THE EXACT SAME code as full training.\n",
    "# The ONLY differences are: fewer timesteps, separate model/env instances.\n",
    "# Takes ~2-5 minutes depending on hardware.\n",
    "\n",
    "TRIAL_TIMESTEPS = 50_000  # Short run for verification\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRIAL RUN - End-to-End Verification\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Trial timesteps: {TRIAL_TIMESTEPS:,}\")\n",
    "print(f\"Using same Config values as full training\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Create trial directories (separate from main training)\n",
    "trial_log_dir = Path(\"./logs/trial_run\")\n",
    "trial_model_dir = Path(\"./models/trial_run\")\n",
    "trial_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "trial_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create environments using THE SAME function as full training\n",
    "# (Using 4 envs instead of N_ENVS for faster startup in trial)\n",
    "print(\"Creating trial environments...\")\n",
    "trial_n_envs = min(4, Config.N_ENVS)  # Use fewer envs for trial\n",
    "trial_train_env = create_vectorized_env(n_envs=trial_n_envs)\n",
    "trial_eval_env = create_vectorized_env(n_envs=1)\n",
    "print(f\"✓ Trial environments ready ({trial_n_envs} training envs)\")\n",
    "\n",
    "# Create trial model using THE SAME configuration as full training\n",
    "# (Using a separate model instance to not affect the main model)\n",
    "print(\"\\nCreating trial model...\")\n",
    "\n",
    "# Use same learning rate setup as full training\n",
    "if Config.USE_LR_SCHEDULE:\n",
    "    trial_learning_rate = linear_schedule(Config.LEARNING_RATE)\n",
    "else:\n",
    "    trial_learning_rate = Config.LEARNING_RATE\n",
    "\n",
    "trial_model = PPO(\n",
    "    policy='CnnPolicy',\n",
    "    env=trial_train_env,\n",
    "    learning_rate=trial_learning_rate,\n",
    "    n_steps=Config.N_STEPS,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    n_epochs=Config.N_EPOCHS,\n",
    "    gamma=Config.GAMMA,\n",
    "    gae_lambda=Config.GAE_LAMBDA,\n",
    "    clip_range=Config.CLIP_RANGE,\n",
    "    clip_range_vf=Config.CLIP_RANGE_VF,\n",
    "    ent_coef=Config.ENT_COEF,\n",
    "    vf_coef=Config.VF_COEF,\n",
    "    max_grad_norm=Config.MAX_GRAD_NORM,\n",
    "    policy_kwargs=policy_kwargs,  # Same custom CNN\n",
    "    tensorboard_log=None,  # No tensorboard for trial (faster)\n",
    "    verbose=0,  # Less verbose for trial\n",
    "    device=Config.DEVICE\n",
    ")\n",
    "print(f\"✓ Trial model created on {Config.DEVICE}\")\n",
    "\n",
    "# Create callbacks using THE SAME classes as full training\n",
    "# (Just with different directories and more frequent heartbeat)\n",
    "trial_metrics_callback = TrainingMetricsCallback(\n",
    "    check_freq=5000,\n",
    "    log_dir=trial_log_dir,\n",
    "    verbose=1\n",
    ")\n",
    "trial_heartbeat_callback = HeartbeatCallback(\n",
    "    interval=15,  # More frequent heartbeat for short trial\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "trial_callbacks = [trial_metrics_callback, trial_heartbeat_callback]\n",
    "\n",
    "# Train using THE SAME method as full training\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Starting trial training...\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "trial_start_time = time.time()\n",
    "sys.stdout.flush()\n",
    "\n",
    "try:\n",
    "    trial_model.learn(\n",
    "        total_timesteps=TRIAL_TIMESTEPS,\n",
    "        callback=trial_callbacks,\n",
    "        log_interval=Config.LOG_INTERVAL,\n",
    "        progress_bar=False  # Disabled: conflicts with Jupyter/Rich\n",
    "    )\n",
    "    \n",
    "    trial_training_time = time.time() - trial_start_time\n",
    "    print(f\"\\n✓ Trial training complete in {trial_training_time:.1f}s\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n⚠ Trial interrupted by user\")\n",
    "    trial_train_env.close()\n",
    "    trial_eval_env.close()\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n✗ Trial training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    trial_train_env.close()\n",
    "    trial_eval_env.close()\n",
    "    raise\n",
    "\n",
    "# Evaluate using THE SAME function as full training\n",
    "# Do BOTH deterministic and stochastic evaluation\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Evaluating trial agent (DETERMINISTIC)...\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "trial_eval_det = evaluate_model(\n",
    "    trial_model, \n",
    "    trial_eval_env, \n",
    "    n_episodes=5,\n",
    "    deterministic=True, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Evaluating trial agent (STOCHASTIC)...\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "trial_eval_stoch = evaluate_model(\n",
    "    trial_model, \n",
    "    trial_eval_env, \n",
    "    n_episodes=5,\n",
    "    deterministic=False,  # Stochastic to see variance\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Metric':<20} {'Deterministic':>15} {'Stochastic':>15}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Mean Reward':<20} {trial_eval_det['mean_reward']:>15.2f} {trial_eval_stoch['mean_reward']:>15.2f}\")\n",
    "print(f\"{'Std Reward':<20} {trial_eval_det['std_reward']:>15.2f} {trial_eval_stoch['std_reward']:>15.2f}\")\n",
    "print(f\"{'Mean X Position':<20} {trial_eval_det['mean_x_pos']:>15.0f} {trial_eval_stoch['mean_x_pos']:>15.0f}\")\n",
    "print(f\"{'Std X Position':<20} {trial_eval_det['std_x_pos']:>15.1f} {trial_eval_stoch['std_x_pos']:>15.1f}\")\n",
    "\n",
    "# Use deterministic results for reporting\n",
    "trial_eval_results = trial_eval_det\n",
    "\n",
    "# Plot trial results (same style as full training)\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "print(\"Plotting trial results...\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "if len(trial_metrics_callback.metrics['timesteps']) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    fig.suptitle('Trial Run Training Progress', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    timesteps = trial_metrics_callback.metrics['timesteps']\n",
    "    \n",
    "    # Rewards\n",
    "    axes[0, 0].plot(timesteps, trial_metrics_callback.metrics['episode_rewards'], 'b-', linewidth=1.5)\n",
    "    axes[0, 0].set_xlabel('Timesteps')\n",
    "    axes[0, 0].set_ylabel('Mean Episode Reward')\n",
    "    axes[0, 0].set_title('Episode Rewards')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Episode lengths\n",
    "    axes[0, 1].plot(timesteps, trial_metrics_callback.metrics['episode_lengths'], 'g-', linewidth=1.5)\n",
    "    axes[0, 1].set_xlabel('Timesteps')\n",
    "    axes[0, 1].set_ylabel('Mean Episode Length')\n",
    "    axes[0, 1].set_title('Episode Lengths')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # X positions - this should now show actual progress!\n",
    "    axes[1, 0].plot(timesteps, trial_metrics_callback.metrics['x_positions'], 'r-', linewidth=1.5)\n",
    "    axes[1, 0].set_xlabel('Timesteps')\n",
    "    axes[1, 0].set_ylabel('Mean X Position')\n",
    "    axes[1, 0].set_title('Distance Traveled (Should Increase!)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Flags\n",
    "    axes[1, 1].plot(timesteps, trial_metrics_callback.metrics['flags_gotten'], 'm-', linewidth=1.5)\n",
    "    axes[1, 1].set_xlabel('Timesteps')\n",
    "    axes[1, 1].set_ylabel('Flag Rate')\n",
    "    axes[1, 1].set_title('Level Completion Rate')\n",
    "    axes[1, 1].set_ylim(-0.05, 1.05)\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(trial_log_dir / 'trial_training_plot.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"✓ Plot saved to {trial_log_dir / 'trial_training_plot.png'}\")\n",
    "else:\n",
    "    print(\"⚠ Not enough data points to plot (try increasing TRIAL_TIMESTEPS)\")\n",
    "\n",
    "# Save trial model\n",
    "trial_model.save(trial_model_dir / 'trial_model')\n",
    "print(f\"\\n✓ Trial model saved to {trial_model_dir / 'trial_model'}\")\n",
    "\n",
    "# Clean up trial environments\n",
    "trial_train_env.close()\n",
    "trial_eval_env.close()\n",
    "print(\"✓ Trial environments closed\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRIAL RUN COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training time: {trial_training_time:.1f}s\")\n",
    "print(f\"Final mean reward: {trial_eval_results['mean_reward']:.2f} ± {trial_eval_results['std_reward']:.2f}\")\n",
    "print(f\"Final mean x_pos: {trial_eval_results['mean_x_pos']:.0f} ± {trial_eval_results['std_x_pos']:.1f}\")\n",
    "print(f\"Final completion rate: {trial_eval_results['completion_rate']*100:.1f}%\")\n",
    "\n",
    "# Check if training metrics show improvement\n",
    "if len(trial_metrics_callback.metrics['x_positions']) >= 2:\n",
    "    x_start = trial_metrics_callback.metrics['x_positions'][0]\n",
    "    x_end = trial_metrics_callback.metrics['x_positions'][-1]\n",
    "    x_improvement = x_end - x_start\n",
    "    print(f\"\\nTraining Progress:\")\n",
    "    print(f\"  X Position: {x_start:.0f} -> {x_end:.0f} (change: {x_improvement:+.0f})\")\n",
    "    if x_improvement > 50:\n",
    "        print(\"  ✓ Agent is learning to move further!\")\n",
    "    elif x_improvement > 0:\n",
    "        print(\"  ⚠ Slight improvement, more training may help\")\n",
    "    else:\n",
    "        print(\"  ⚠ No clear improvement in x_pos - check if agent is learning\")\n",
    "\n",
    "print(\"\\n✓ Everything works! You can now run the full training.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11b. Full Training\n",
    "\n",
    "**⚠️ Run the Trial Run (Section 11a) first to verify everything works!**\n",
    "\n",
    "This runs the full training for the configured number of timesteps.\n",
    "Training includes:\n",
    "- Periodic checkpoints (every 50k steps)\n",
    "- Best model saving\n",
    "- Heartbeat status updates (every 60 seconds)\n",
    "- Metrics saved to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FULL TRAINING\n",
    "# ============================================================================\n",
    "# Run this after the trial run confirms everything works.\n",
    "# Uses the pre-created model from Section 10.\n",
    "\n",
    "# Set up callbacks (same classes as trial run)\n",
    "metrics_callback = TrainingMetricsCallback(\n",
    "    check_freq=5000,\n",
    "    log_dir=Config.LOG_DIR,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=Config.SAVE_FREQ // Config.N_ENVS,\n",
    "    save_path=str(Config.MODEL_DIR),\n",
    "    name_prefix='ppo_mario'\n",
    ")\n",
    "\n",
    "best_model_callback = SaveBestModelCallback(\n",
    "    save_path=Config.MODEL_DIR,\n",
    "    check_freq=10000,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# HeartbeatCallback prints status every 60 seconds to prevent silent timeouts\n",
    "heartbeat_callback = HeartbeatCallback(interval=60, verbose=1)\n",
    "\n",
    "callbacks = [metrics_callback, checkpoint_callback, best_model_callback, heartbeat_callback]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STARTING FULL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total timesteps: {Config.TOTAL_TIMESTEPS:,}\")\n",
    "print(f\"Number of environments: {Config.N_ENVS}\")\n",
    "print(f\"Steps per update: {Config.N_STEPS * Config.N_ENVS:,}\")\n",
    "print(f\"Checkpoints saved to: {Config.MODEL_DIR}\")\n",
    "print(f\"Metrics CSV saved to: {Config.LOG_DIR}\")\n",
    "\n",
    "# Only show TensorBoard info if it's enabled\n",
    "if tb_log_path:\n",
    "    print(f\"TensorBoard logs: {Config.TENSORBOARD_LOG}\")\n",
    "    print(\"\\nTo view TensorBoard, run:\")\n",
    "    print(f\"  tensorboard --logdir {Config.TENSORBOARD_LOG.parent}\")\n",
    "else:\n",
    "    print(\"TensorBoard logging: Disabled (using CSV metrics only)\")\n",
    "\n",
    "print(\"\\n[Heartbeat callback will print status every 60 seconds]\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Flush output before training starts\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    model.learn(\n",
    "        total_timesteps=Config.TOTAL_TIMESTEPS,\n",
    "        callback=callbacks,\n",
    "        log_interval=Config.LOG_INTERVAL,\n",
    "        progress_bar=False  # Disabled: conflicts with Jupyter/Rich\n",
    "    )\n",
    "    \n",
    "    # Calculate training time\n",
    "    training_time = time.time() - start_time\n",
    "    hours = int(training_time // 3600)\n",
    "    minutes = int((training_time % 3600) // 60)\n",
    "    seconds = int(training_time % 60)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total training time: {hours}h {minutes}m {seconds}s\")\n",
    "    print(f\"Total timesteps: {model.num_timesteps:,}\")\n",
    "    \n",
    "    # Save final model\n",
    "    final_model_path = Config.MODEL_DIR / 'final_model'\n",
    "    model.save(final_model_path)\n",
    "    print(f\"\\n✓ Final model saved to: {final_model_path}\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n⚠ Training interrupted by user\")\n",
    "    interrupted_path = Config.MODEL_DIR / 'interrupted_model'\n",
    "    model.save(interrupted_path)\n",
    "    print(f\"✓ Model saved to: {interrupted_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n✗ Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Try to save model even on error\n",
    "    try:\n",
    "        error_path = Config.MODEL_DIR / 'error_model'\n",
    "        error_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        model.save(error_path)\n",
    "        print(f\"\\n✓ Model saved despite error: {error_path}\")\n",
    "    except:\n",
    "        print(\"Could not save model after error\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Plot Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PLOT TRAINING RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "def plot_training_results(metrics: Dict, window_size: int = 100, save_path: Path = None):\n",
    "    \"\"\"\n",
    "    Plot comprehensive training results.\n",
    "    \n",
    "    Args:\n",
    "        metrics: Dictionary containing training metrics\n",
    "        window_size: Window size for rolling average\n",
    "        save_path: Path to save the figure\n",
    "    \"\"\"\n",
    "    timesteps = np.array(metrics['timesteps'])\n",
    "    rewards = np.array(metrics['episode_rewards'])\n",
    "    lengths = np.array(metrics['episode_lengths'])\n",
    "    x_positions = np.array(metrics['x_positions'])\n",
    "    flags = np.array(metrics['flags_gotten'])\n",
    "    \n",
    "    # Calculate rolling averages\n",
    "    def rolling_average(data, window):\n",
    "        return pd.Series(data).rolling(window=window, min_periods=1).mean().values\n",
    "    \n",
    "    rewards_smooth = rolling_average(rewards, window_size)\n",
    "    lengths_smooth = rolling_average(lengths, window_size)\n",
    "    x_pos_smooth = rolling_average(x_positions, window_size)\n",
    "    flags_cumsum = np.cumsum(flags)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle('PPO Baseline Training Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Episode Rewards\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.plot(timesteps, rewards, alpha=0.3, color='blue', label='Episode Reward')\n",
    "    ax1.plot(timesteps, rewards_smooth, color='blue', linewidth=2, label=f'Rolling Avg ({window_size} ep)')\n",
    "    ax1.set_xlabel('Timesteps')\n",
    "    ax1.set_ylabel('Reward')\n",
    "    ax1.set_title('Episode Rewards')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Episode Lengths\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(timesteps, lengths, alpha=0.3, color='green', label='Episode Length')\n",
    "    ax2.plot(timesteps, lengths_smooth, color='green', linewidth=2, label=f'Rolling Avg ({window_size} ep)')\n",
    "    ax2.set_xlabel('Timesteps')\n",
    "    ax2.set_ylabel('Length (steps)')\n",
    "    ax2.set_title('Episode Lengths')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # X Position Progress\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(timesteps, x_positions, alpha=0.3, color='orange', label='X Position')\n",
    "    ax3.plot(timesteps, x_pos_smooth, color='orange', linewidth=2, label=f'Rolling Avg ({window_size} ep)')\n",
    "    ax3.axhline(y=3161, color='red', linestyle='--', label='Level End (~3161)')\n",
    "    ax3.set_xlabel('Timesteps')\n",
    "    ax3.set_ylabel('X Position')\n",
    "    ax3.set_title('Maximum X Position (Progress)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Flags Gotten (Cumulative)\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.plot(timesteps, flags_cumsum, color='purple', linewidth=2)\n",
    "    ax4.fill_between(timesteps, flags_cumsum, alpha=0.3, color='purple')\n",
    "    ax4.set_xlabel('Timesteps')\n",
    "    ax4.set_ylabel('Cumulative Flags')\n",
    "    ax4.set_title('Levels Completed (Flags Gotten)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"✓ Figure saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Episodes: {len(rewards)}\")\n",
    "    print(f\"Total Timesteps: {timesteps[-1] if len(timesteps) > 0 else 0:,}\")\n",
    "    print(f\"\\nReward Statistics:\")\n",
    "    print(f\"  Mean: {np.mean(rewards):.2f}\")\n",
    "    print(f\"  Std: {np.std(rewards):.2f}\")\n",
    "    print(f\"  Max: {np.max(rewards):.2f}\")\n",
    "    print(f\"  Final 100 ep avg: {np.mean(rewards[-100:]):.2f}\")\n",
    "    print(f\"\\nX Position Statistics:\")\n",
    "    print(f\"  Mean: {np.mean(x_positions):.2f}\")\n",
    "    print(f\"  Max: {np.max(x_positions):.2f}\")\n",
    "    print(f\"  Final 100 ep avg: {np.mean(x_positions[-100:]):.2f}\")\n",
    "    print(f\"\\nLevel Completions: {int(np.sum(flags))}\")\n",
    "\n",
    "\n",
    "# Plot results\n",
    "metrics = metrics_callback.get_metrics()\n",
    "if len(metrics['episode_rewards']) > 0:\n",
    "    plot_training_results(\n",
    "        metrics, \n",
    "        window_size=100, \n",
    "        save_path=Config.LOG_DIR / 'training_results.png'\n",
    "    )\n",
    "else:\n",
    "    print(\"No training data to plot yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Evaluate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATE TRAINED MODEL (Full Training)\n",
    "# ============================================================================\n",
    "# Note: evaluate_model function is defined in Section 10b\n",
    "\n",
    "print(\"Evaluating trained model...\\n\")\n",
    "eval_results = evaluate_model(model, eval_env, n_episodes=10, deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Watch Agent Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# WATCH AGENT PLAY (RECORD EPISODE)\n",
    "# ============================================================================\n",
    "\n",
    "def record_episode(\n",
    "    model,\n",
    "    n_steps: int = 1000,\n",
    "    deterministic: bool = False,\n",
    "    show_every: int = 50\n",
    ") -> Tuple[List[np.ndarray], Dict]:\n",
    "    \"\"\"\n",
    "    Record an episode and return frames for visualization.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        n_steps: Maximum number of steps\n",
    "        deterministic: Use deterministic actions\n",
    "        show_every: Show frame every N steps\n",
    "    \n",
    "    Returns:\n",
    "        List of frames and episode info\n",
    "    \"\"\"\n",
    "    # Create environment without preprocessing for visualization\n",
    "    vis_env = gym_super_mario_bros.make(Config.ENV_NAME)\n",
    "    vis_env = JoypadSpace(vis_env, Config.ACTION_SPACE)\n",
    "    \n",
    "    # Also create preprocessed env for model\n",
    "    model_env = create_vectorized_env(n_envs=1)\n",
    "    \n",
    "    frames = []\n",
    "    obs_vis = vis_env.reset()\n",
    "    obs_model = model_env.reset()\n",
    "    \n",
    "    if isinstance(obs_vis, tuple):\n",
    "        obs_vis, _ = obs_vis\n",
    "    \n",
    "    frames.append(obs_vis.copy())\n",
    "    \n",
    "    total_reward = 0\n",
    "    step_count = 0\n",
    "    done = False\n",
    "    max_x_pos = 0\n",
    "    flag_get = False\n",
    "    \n",
    "    while not done and step_count < n_steps:\n",
    "        # Get action from model using preprocessed observation\n",
    "        action, _ = model.predict(obs_model, deterministic=deterministic)\n",
    "        \n",
    "        # Step both environments\n",
    "        result_vis = vis_env.step(action[0] if isinstance(action, np.ndarray) else action)\n",
    "        obs_model, reward, done_model, info_model = model_env.step(action)\n",
    "        \n",
    "        # Handle gymnasium 5-tuple return\n",
    "        if len(result_vis) == 5:\n",
    "            obs_vis, reward_vis, terminated, truncated, info_vis = result_vis\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            obs_vis, reward_vis, done, info_vis = result_vis\n",
    "        \n",
    "        total_reward += reward_vis\n",
    "        step_count += 1\n",
    "        max_x_pos = max(max_x_pos, info_vis.get('x_pos', 0))\n",
    "        \n",
    "        if info_vis.get('flag_get', False):\n",
    "            flag_get = True\n",
    "        \n",
    "        frames.append(obs_vis.copy())\n",
    "        \n",
    "        # Show progress\n",
    "        if step_count % show_every == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(obs_vis)\n",
    "            plt.title(f\"Step: {step_count}, Reward: {total_reward:.2f}, X: {max_x_pos}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    \n",
    "    vis_env.close()\n",
    "    model_env.close()\n",
    "    \n",
    "    episode_info = {\n",
    "        'total_reward': total_reward,\n",
    "        'steps': step_count,\n",
    "        'max_x_pos': max_x_pos,\n",
    "        'flag_get': flag_get\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n✓ Episode recorded!\")\n",
    "    print(f\"  Total Reward: {total_reward:.2f}\")\n",
    "    print(f\"  Steps: {step_count}\")\n",
    "    print(f\"  Max X Position: {max_x_pos}\")\n",
    "    print(f\"  Flag Get: {'Yes!' if flag_get else 'No'}\")\n",
    "    \n",
    "    return frames, episode_info\n",
    "\n",
    "\n",
    "# Record an episode\n",
    "print(\"Recording episode...\")\n",
    "frames, episode_info = record_episode(model, n_steps=2000, show_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save/Load Model Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE/LOAD UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def save_complete_model(model, config, metrics, save_dir: Path):\n",
    "    \"\"\"\n",
    "    Save model along with configuration and metrics.\n",
    "    \"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model.save(save_dir / 'model')\n",
    "    \n",
    "    # Save config\n",
    "    config_dict = {\n",
    "        'ENV_NAME': config.ENV_NAME,\n",
    "        'ACTION_SPACE': str(config.ACTION_SPACE),\n",
    "        'FRAME_SKIP': config.FRAME_SKIP,\n",
    "        'FRAME_STACK': config.FRAME_STACK,\n",
    "        'RESIZE_SHAPE': config.RESIZE_SHAPE,\n",
    "        'LEARNING_RATE': config.LEARNING_RATE,\n",
    "        'N_STEPS': config.N_STEPS,\n",
    "        'BATCH_SIZE': config.BATCH_SIZE,\n",
    "        'N_EPOCHS': config.N_EPOCHS,\n",
    "        'GAMMA': config.GAMMA,\n",
    "        'GAE_LAMBDA': config.GAE_LAMBDA,\n",
    "        'CLIP_RANGE': config.CLIP_RANGE,\n",
    "        'ENT_COEF': config.ENT_COEF,\n",
    "        'TOTAL_TIMESTEPS': config.TOTAL_TIMESTEPS,\n",
    "        'N_ENVS': config.N_ENVS,\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(save_dir / 'config.json', 'w') as f:\n",
    "        json.dump(config_dict, f, indent=2)\n",
    "    \n",
    "    # Save metrics\n",
    "    if metrics:\n",
    "        metrics_df = pd.DataFrame(metrics)\n",
    "        metrics_df.to_csv(save_dir / 'training_metrics.csv', index=False)\n",
    "    \n",
    "    print(f\"✓ Complete model saved to: {save_dir}\")\n",
    "\n",
    "\n",
    "def load_model(model_path: Path, env=None):\n",
    "    \"\"\"\n",
    "    Load a saved model.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to saved model\n",
    "        env: Environment (optional, for continued training)\n",
    "    \n",
    "    Returns:\n",
    "        Loaded PPO model\n",
    "    \"\"\"\n",
    "    model = PPO.load(model_path, env=env)\n",
    "    print(f\"✓ Model loaded from: {model_path}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Save complete model\n",
    "save_complete_model(\n",
    "    model=model,\n",
    "    config=Config,\n",
    "    metrics=metrics_callback.get_metrics(),\n",
    "    save_dir=Config.MODEL_DIR / 'complete'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Quick Hyperparameter Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT FRAMEWORK\n",
    "# ============================================================================\n",
    "# Use this for ablation studies and hyperparameter experiments.\n",
    "\n",
    "def run_experiment(\n",
    "    experiment_name: str,\n",
    "    learning_rate: float = Config.LEARNING_RATE,\n",
    "    n_steps: int = Config.N_STEPS,\n",
    "    batch_size: int = Config.BATCH_SIZE,\n",
    "    n_epochs: int = Config.N_EPOCHS,\n",
    "    gamma: float = Config.GAMMA,\n",
    "    gae_lambda: float = Config.GAE_LAMBDA,\n",
    "    clip_range: float = Config.CLIP_RANGE,\n",
    "    ent_coef: float = Config.ENT_COEF,\n",
    "    n_envs: int = 4,\n",
    "    total_timesteps: int = 100_000,\n",
    "    env_name: str = Config.ENV_NAME,\n",
    "    action_space = Config.ACTION_SPACE,\n",
    "    verbose: int = 1\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run a single experiment with specified hyperparameters.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with experiment results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running Experiment: {experiment_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create environment\n",
    "    env = create_vectorized_env(\n",
    "        n_envs=n_envs,\n",
    "        env_name=env_name,\n",
    "        action_space=action_space\n",
    "    )\n",
    "    \n",
    "    # Create model (no tensorboard logging for experiments to avoid issues)\n",
    "    exp_model = PPO(\n",
    "        policy='CnnPolicy',\n",
    "        env=env,\n",
    "        learning_rate=learning_rate,\n",
    "        n_steps=n_steps,\n",
    "        batch_size=batch_size,\n",
    "        n_epochs=n_epochs,\n",
    "        gamma=gamma,\n",
    "        gae_lambda=gae_lambda,\n",
    "        clip_range=clip_range,\n",
    "        ent_coef=ent_coef,\n",
    "        policy_kwargs=policy_kwargs,\n",
    "        tensorboard_log=None,  # Disable tensorboard for experiments\n",
    "        verbose=verbose,\n",
    "        device=Config.DEVICE\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    exp_callback = [\n",
    "        TrainingMetricsCallback(check_freq=10000, verbose=verbose), \n",
    "        HeartbeatCallback(interval=30, verbose=verbose)\n",
    "    ]\n",
    "    start_time = time.time()\n",
    "    \n",
    "    exp_model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback=exp_callback,\n",
    "        progress_bar=False  # Disabled: conflicts with Jupyter/Rich\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_env = create_vectorized_env(n_envs=1, env_name=env_name, action_space=action_space)\n",
    "    eval_results = evaluate_model(exp_model, eval_env, n_episodes=5, verbose=False)\n",
    "    \n",
    "    # Clean up\n",
    "    env.close()\n",
    "    eval_env.close()\n",
    "    \n",
    "    results = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'training_time': training_time,\n",
    "        'mean_reward': eval_results['mean_reward'],\n",
    "        'std_reward': eval_results['std_reward'],\n",
    "        'mean_x_pos': eval_results['mean_x_pos'],\n",
    "        'completion_rate': eval_results['completion_rate'],  # Already a fraction\n",
    "        'hyperparameters': {\n",
    "            'learning_rate': learning_rate,\n",
    "            'n_steps': n_steps,\n",
    "            'batch_size': batch_size,\n",
    "            'n_epochs': n_epochs,\n",
    "            'gamma': gamma,\n",
    "            'gae_lambda': gae_lambda,\n",
    "            'clip_range': clip_range,\n",
    "            'ent_coef': ent_coef,\n",
    "            'n_envs': n_envs,\n",
    "            'total_timesteps': total_timesteps\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Mean reward: {results['mean_reward']:.2f} +/- {results['std_reward']:.2f}\")\n",
    "    print(f\"  Mean x_pos: {results['mean_x_pos']:.0f}\")\n",
    "    print(f\"  Completion rate: {results['completion_rate']*100:.1f}%\")  # Multiply for display\n",
    "    print(f\"  Training time: {training_time:.1f}s\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def compare_experiments(results_list: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compare multiple experiment results.\n",
    "    \n",
    "    Args:\n",
    "        results_list: List of result dictionaries from run_experiment\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with comparison\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for r in results_list:\n",
    "        row = {\n",
    "            'Experiment': r['experiment_name'],\n",
    "            'Mean Reward': f\"{r['mean_reward']:.2f}\",\n",
    "            'Std Reward': f\"{r['std_reward']:.2f}\",\n",
    "            'Mean X Pos': f\"{r['mean_x_pos']:.0f}\",\n",
    "            'Completion %': f\"{r['completion_rate']*100:.1f}%\",  # Multiply for display\n",
    "            'Train Time (s)': f\"{r['training_time']:.1f}\"\n",
    "        }\n",
    "        rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage (commented out):\n",
    "# results = []\n",
    "# \n",
    "# # Test different learning rates\n",
    "# for lr in [1e-4, 2.5e-4, 5e-4]:\n",
    "#     result = run_experiment(\n",
    "#         experiment_name=f\"lr_{lr}\",\n",
    "#         learning_rate=lr,\n",
    "#         total_timesteps=100_000\n",
    "#     )\n",
    "#     results.append(result)\n",
    "# \n",
    "# # Compare results\n",
    "# comparison_df = compare_experiments(results)\n",
    "# display(comparison_df)\n",
    "\n",
    "print(\"✓ Experiment framework ready!\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"  result = run_experiment('my_experiment', learning_rate=1e-4, total_timesteps=100_000)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CLEANUP\n",
    "# ============================================================================\n",
    "\n",
    "# Close environments\n",
    "try:\n",
    "    train_env.close()\n",
    "    eval_env.close()\n",
    "    print(\"✓ Environments closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel saved to: {Config.MODEL_DIR}\")\n",
    "print(f\"Metrics CSV saved to: {Config.LOG_DIR}\")\n",
    "\n",
    "# Only show TensorBoard info if it was enabled\n",
    "if tb_log_path:\n",
    "    print(f\"TensorBoard logs: {Config.TENSORBOARD_LOG}\")\n",
    "    print(\"\\nTo view TensorBoard:\")\n",
    "    print(f\"  tensorboard --logdir {Config.TENSORBOARD_LOG.parent}\")\n",
    "else:\n",
    "    print(\"\\nTensorBoard was disabled. View metrics in CSV files at:\")\n",
    "    print(f\"  {Config.LOG_DIR}\")\n",
    "\n",
    "print(\"\\nTo continue training, load the model with:\")\n",
    "print(f\"  model = PPO.load('{Config.MODEL_DIR}/final_model')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD AND VISUALIZE A SAVED MODEL\n",
    "# ============================================================================\n",
    "\n",
    "# MAKE SURE TO RUN\n",
    "# Cells 1-10 AND cell 14 so all the dependencies for this code are loaded\n",
    "# Run multiple times for best results\n",
    "\n",
    "from pathlib import Path\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "model = PPO.load(\"models/ppo_curriculum1-2/best_model\")\n",
    "\n",
    "# if testing on level 1-2, change this line\n",
    "original_env = Config.ENV_NAME\n",
    "Config.ENV_NAME = 'SuperMarioBros-1-2-v0'\n",
    "\n",
    "\n",
    "eval_env = create_vectorized_env(\n",
    "    n_envs=1,\n",
    "    env_name='SuperMarioBros-1-2-v0',  \n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "mean_reward, std_reward = evaluate_policy(\n",
    "    model, \n",
    "    eval_env, \n",
    "    n_eval_episodes=20,\n",
    "    deterministic=True\n",
    ")\n",
    "print(f\"\\n✓ Evaluation Results:\")\n",
    "print(f\"  Mean Reward: {mean_reward:.2f} ± {std_reward:.2f}\")\n",
    "\n",
    "# Watch agent play (using record_episode function already in notebook)\n",
    "frames, episode_info = record_episode(\n",
    "    model,\n",
    "    n_steps=10000,\n",
    "    deterministic=False,\n",
    "    show_every=5\n",
    ")\n",
    "\n",
    "Config.ENV_NAME = original_env"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Mario RL)",
   "language": "python",
   "name": "mario_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
